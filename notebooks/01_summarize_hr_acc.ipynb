{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "911012b0",
   "metadata": {},
   "source": [
    "# Beiwe Sample Dataset Accelerometer EDA Pt. 2\n",
    "\n",
    "Prototype helper functions to load and summarize an hour's worth of accelerometer data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1a709d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# TODO: move to its own script\n",
    "def summarize_hourly_file(file_path, verbose=True):\n",
    "    \"\"\"Analyze a single hourly accelerometer CSV file.\"\"\"\n",
    "    try:\n",
    "        # Check if file exists\n",
    "        if not os.path.exists(file_path):\n",
    "            if verbose:\n",
    "                print(f\"Missing: {os.path.basename(file_path)}\")\n",
    "            return None\n",
    "        # If it exists read CSV\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Handle empty files\n",
    "        if len(df) == 0:\n",
    "            if verbose:\n",
    "                print(f\"Empty: {os.path.basename(file_path)}\")\n",
    "            return None\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")    \n",
    "\n",
    "    # Convert timestamps\n",
    "    df['datetime_utc'] = pd.to_datetime(df['timestamp'], unit='ms', utc=True)\n",
    "\n",
    "    # Compute magnitude\n",
    "    df['magnitude'] = np.sqrt(df['x']**2 + df['y']**2 + df['z']**2)\n",
    "\n",
    "    # Calculate metrics\n",
    "    n_rows = len(df)\n",
    "    start_time = df['datetime_utc'].iloc[0]\n",
    "    end_time = df['datetime_utc'].iloc[-1]\n",
    "    \n",
    "    # Duration in minutes\n",
    "    duration_sec = (end_time - start_time).total_seconds()\n",
    "    duration_min = duration_sec / 60\n",
    "    \n",
    "    # Sampling time in minutes (at 10 Hz)\n",
    "    sampling_min = n_rows / 10 / 60\n",
    "    \n",
    "    # Duty cycle\n",
    "    duty_cycle = sampling_min / duration_min\n",
    "    \n",
    "    # Count bursts\n",
    "    df['time_diff_ms'] = df['timestamp'].diff()\n",
    "    gaps = df['time_diff_ms'] > 1000 \n",
    "    gaps_count = gaps.sum()\n",
    "    n_bursts = gaps_count + 1\n",
    "    \n",
    "    # Mean magnitude\n",
    "    mean_magnitude = df['magnitude'].mean()\n",
    "\n",
    "    return {\n",
    "        'n_rows': n_rows,\n",
    "        'start_time': start_time,\n",
    "        'end_time': end_time,\n",
    "        'duration_min': duration_min,\n",
    "        'sampling_min': sampling_min,\n",
    "        'duty_cycle': duty_cycle,\n",
    "       'n_bursts': n_bursts,\n",
    "        'mean_magnitude': mean_magnitude\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f68631",
   "metadata": {},
   "source": [
    "Check that summarize_hourly_file() works on the hr_9 CSV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93f67d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_rows': 18090, 'start_time': Timestamp('2022-03-26 09:00:38.792000+0000', tz='UTC'), 'end_time': Timestamp('2022-03-26 09:59:39.055000+0000', tz='UTC'), 'duration_min': 59.00438333333333, 'sampling_min': 30.15, 'duty_cycle': 0.5109789865894144, 'n_bursts': np.int64(30), 'mean_magnitude': np.float64(1.0069258994313353)}\n"
     ]
    }
   ],
   "source": [
    "base_path = \"/n/home01/egraff/sample_imputation/data/raw/3si9xdvl/accelerometer/\"\n",
    "test_file_path = base_path + \"2022-03-26 09_00_00+00_00.csv\"\n",
    "\n",
    "result = summarize_hourly_file(test_file_path)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be83b39",
   "metadata": {},
   "source": [
    "Now try on different files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a28c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============================================================================\n",
      "\n",
      "Hour 00:00\n",
      "-------------------------------------------------------------------------------\n",
      "Rows: 602\n",
      "Time span: 00:26:29 to 00:27:29\n",
      "Duration: 1.0 min\n",
      "Sampling time: 1.0 min\n",
      "Duty cycle: 100.6%\n",
      "Bursts: 1\n",
      "Mean magnitude: 1.0107 g\n",
      "\n",
      "Hour 09:00\n",
      "-------------------------------------------------------------------------------\n",
      "Rows: 18,090\n",
      "Time span: 09:00:38 to 09:59:39\n",
      "Duration: 59.0 min\n",
      "Sampling time: 30.1 min\n",
      "Duty cycle: 51.1%\n",
      "Bursts: 30\n",
      "Mean magnitude: 1.0069 g\n",
      "\n",
      "Hour 16:00\n",
      "-------------------------------------------------------------------------------\n",
      "Rows: 9,049\n",
      "Time span: 16:30:01 to 16:59:02\n",
      "Duration: 29.0 min\n",
      "Sampling time: 15.1 min\n",
      "Duty cycle: 52.0%\n",
      "Bursts: 15\n",
      "Mean magnitude: 1.0340 g\n",
      "\n",
      "Hour 23:00\n",
      "-------------------------------------------------------------------------------\n",
      "Rows: 11,455\n",
      "Time span: 23:22:06 to 23:59:06\n",
      "Duration: 37.0 min\n",
      "Sampling time: 19.1 min\n",
      "Duty cycle: 51.6%\n",
      "Bursts: 19\n",
      "Mean magnitude: 1.0090 g\n",
      "\n",
      "===============================================================================\n"
     ]
    }
   ],
   "source": [
    "test_hours = [0, 9, 16, 23]  # Variety: short, full, partial, end-of-day\n",
    "\n",
    "print(\"\\n\" + \"=\"*79)\n",
    "for hour in test_hours:\n",
    "    file_path = base_path + f\"2022-03-26 {hour:02d}_00_00+00_00.csv\"\n",
    "    print(f\"\\nHour {hour:02d}:00\")\n",
    "    print(\"-\" *79)\n",
    "    \n",
    "    try:\n",
    "        result = summarize_hourly_file(file_path)\n",
    "        \n",
    "        print(f\"Rows: {result['n_rows']:, }\")\n",
    "        print(f\"Time span: {result['start_time'].strftime('%H:%M:%S')} to {result['end_time'].strftime('%H:%M:%S')}\")\n",
    "        print(f\"Duration: {result['duration_min']:.1f} min\")\n",
    "        print(f\"Sampling time: {result['sampling_min']:.1f} min\")\n",
    "        print(f\"Duty cycle: {result['duty_cycle']:.1%}\")\n",
    "        print(f\"Bursts: {result['n_bursts']}\")\n",
    "        print(f\"Mean magnitude: {result['mean_magnitude']:.4f} g\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71403209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing: 2022-03-26 01_00_00+00_00.csv\n",
      "Missing: 2022-03-26 02_00_00+00_00.csv\n",
      "Missing: 2022-03-26 03_00_00+00_00.csv\n",
      "Missing: 2022-03-26 15_00_00+00_00.csv\n",
      "Summarized 20 out of 24 hours\n",
      "\n",
      "   n_rows                       start_time                         end_time  \\\n",
      "0     602 2022-03-26 00:26:29.955000+00:00 2022-03-26 00:27:29.812000+00:00   \n",
      "1    8620 2022-03-26 04:31:15.460000+00:00 2022-03-26 04:59:33.337000+00:00   \n",
      "2   11438 2022-03-26 05:00:33.399000+00:00 2022-03-26 05:59:34.726000+00:00   \n",
      "3   18081 2022-03-26 06:00:34.770000+00:00 2022-03-26 06:59:34.988000+00:00   \n",
      "4   18100 2022-03-26 07:00:35.057000+00:00 2022-03-26 07:59:37.352000+00:00   \n",
      "5   18098 2022-03-26 08:00:37.442000+00:00 2022-03-26 08:59:38.720000+00:00   \n",
      "6   18090 2022-03-26 09:00:38.792000+00:00 2022-03-26 09:59:39.055000+00:00   \n",
      "7   18088 2022-03-26 10:00:39.127000+00:00 2022-03-26 10:59:39.403000+00:00   \n",
      "8   18098 2022-03-26 11:00:39.477000+00:00 2022-03-26 11:59:40.737000+00:00   \n",
      "9   18098 2022-03-26 12:00:40.804000+00:00 2022-03-26 12:59:42.082000+00:00   \n",
      "\n",
      "   duration_min  sampling_min  duty_cycle  n_bursts  mean_magnitude  hour  \\\n",
      "0      0.997617      1.003333    1.005730         1        1.010712     0   \n",
      "1     28.297950     14.366667    0.507693        15        1.013782     4   \n",
      "2     59.022117     19.063333    0.322986        19        1.027005     5   \n",
      "3     59.003633     30.135000    0.510731        30        1.021260     6   \n",
      "4     59.038250     30.166667    0.510968        30        1.005795     7   \n",
      "5     59.021300     30.163333    0.511058        30        1.009025     8   \n",
      "6     59.004383     30.150000    0.510979        30        1.006926     9   \n",
      "7     59.004600     30.146667    0.510921        30        1.007066    10   \n",
      "8     59.021000     30.163333    0.511061        30        1.005270    11   \n",
      "9     59.021300     30.163333    0.511058        30        1.006475    12   \n",
      "\n",
      "         date subject_id  \n",
      "0  2022-03-26   3si9xdvl  \n",
      "1  2022-03-26   3si9xdvl  \n",
      "2  2022-03-26   3si9xdvl  \n",
      "3  2022-03-26   3si9xdvl  \n",
      "4  2022-03-26   3si9xdvl  \n",
      "5  2022-03-26   3si9xdvl  \n",
      "6  2022-03-26   3si9xdvl  \n",
      "7  2022-03-26   3si9xdvl  \n",
      "8  2022-03-26   3si9xdvl  \n",
      "9  2022-03-26   3si9xdvl  \n"
     ]
    }
   ],
   "source": [
    "# Process all 24 hours for subject 3si9xdvl on 2022-03-26\n",
    "date_str = \"2022-03-26\"\n",
    "subject_id = \"3si9xdvl\"\n",
    "# Store results\n",
    "daily_summary = []\n",
    "\n",
    "for hour in range(24):\n",
    "    file_path = base_path + f\"{date_str} {hour:02d}_00_00+00_00.csv\"\n",
    "    \n",
    "    result = summarize_hourly_file(file_path)\n",
    "    \n",
    "    if result is not None:\n",
    "        # Add hour and date info\n",
    "        result['hour'] = hour\n",
    "        result['date'] = date_str\n",
    "        result['subject_id'] = subject_id\n",
    "        daily_summary.append(result)\n",
    "\n",
    "# Convert to df\n",
    "summary_df = pd.DataFrame(daily_summary)\n",
    "\n",
    "print(f\"Summarized {len(summary_df)} out of 24 hours\")\n",
    "print(f\"\\n{summary_df.head(10)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4aa660b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    n_rows                       start_time                         end_time  \\\n",
      "0      602 2022-03-26 00:26:29.955000+00:00 2022-03-26 00:27:29.812000+00:00   \n",
      "1     8620 2022-03-26 04:31:15.460000+00:00 2022-03-26 04:59:33.337000+00:00   \n",
      "2    11438 2022-03-26 05:00:33.399000+00:00 2022-03-26 05:59:34.726000+00:00   \n",
      "3    18081 2022-03-26 06:00:34.770000+00:00 2022-03-26 06:59:34.988000+00:00   \n",
      "4    18100 2022-03-26 07:00:35.057000+00:00 2022-03-26 07:59:37.352000+00:00   \n",
      "5    18098 2022-03-26 08:00:37.442000+00:00 2022-03-26 08:59:38.720000+00:00   \n",
      "6    18090 2022-03-26 09:00:38.792000+00:00 2022-03-26 09:59:39.055000+00:00   \n",
      "7    18088 2022-03-26 10:00:39.127000+00:00 2022-03-26 10:59:39.403000+00:00   \n",
      "8    18098 2022-03-26 11:00:39.477000+00:00 2022-03-26 11:59:40.737000+00:00   \n",
      "9    18098 2022-03-26 12:00:40.804000+00:00 2022-03-26 12:59:42.082000+00:00   \n",
      "10   18090 2022-03-26 13:00:42.146000+00:00 2022-03-26 13:59:42.426000+00:00   \n",
      "11   17487 2022-03-26 14:00:42.494000+00:00 2022-03-26 14:57:42.761000+00:00   \n",
      "12    9049 2022-03-26 16:30:01.212000+00:00 2022-03-26 16:59:02.238000+00:00   \n",
      "13   18086 2022-03-26 17:00:02.354000+00:00 2022-03-26 17:59:02.682000+00:00   \n",
      "14   18085 2022-03-26 18:00:02.755000+00:00 2022-03-26 18:59:03.008000+00:00   \n",
      "15   18081 2022-03-26 19:00:03.154000+00:00 2022-03-26 19:59:04.328000+00:00   \n",
      "16   18075 2022-03-26 20:00:04.423000+00:00 2022-03-26 20:59:04.701000+00:00   \n",
      "17   18065 2022-03-26 21:00:04.751000+00:00 2022-03-26 21:59:06.030000+00:00   \n",
      "18   12650 2022-03-26 22:00:06.120000+00:00 2022-03-26 22:42:06.333000+00:00   \n",
      "19   11455 2022-03-26 23:22:06.540000+00:00 2022-03-26 23:59:06.696000+00:00   \n",
      "\n",
      "    duration_min  sampling_min  duty_cycle  n_bursts  mean_magnitude  hour  \\\n",
      "0       0.997617      1.003333    1.005730         1        1.010712     0   \n",
      "1      28.297950     14.366667    0.507693        15        1.013782     4   \n",
      "2      59.022117     19.063333    0.322986        19        1.027005     5   \n",
      "3      59.003633     30.135000    0.510731        30        1.021260     6   \n",
      "4      59.038250     30.166667    0.510968        30        1.005795     7   \n",
      "5      59.021300     30.163333    0.511058        30        1.009025     8   \n",
      "6      59.004383     30.150000    0.510979        30        1.006926     9   \n",
      "7      59.004600     30.146667    0.510921        30        1.007066    10   \n",
      "8      59.021000     30.163333    0.511061        30        1.005270    11   \n",
      "9      59.021300     30.163333    0.511058        30        1.006475    12   \n",
      "10     59.004667     30.150000    0.510977        30        1.006943    13   \n",
      "11     57.004450     29.145000    0.511276        29        1.006942    14   \n",
      "12     29.017100     15.081667    0.519751        15        1.034027    16   \n",
      "13     59.005467     30.143333    0.510857        30        1.017629    17   \n",
      "14     59.004217     30.141667    0.510839        30        1.000799    18   \n",
      "15     59.019567     30.135000    0.510593        30        1.023990    19   \n",
      "16     59.004633     30.125000    0.510553        30        1.006408    20   \n",
      "17     59.021317     30.108333    0.510126        31        1.089120    21   \n",
      "18     42.003550     21.083333    0.501942        22        1.001337    22   \n",
      "19     37.002600     19.091667    0.515955        19        1.009036    23   \n",
      "\n",
      "          date subject_id  \n",
      "0   2022-03-26   3si9xdvl  \n",
      "1   2022-03-26   3si9xdvl  \n",
      "2   2022-03-26   3si9xdvl  \n",
      "3   2022-03-26   3si9xdvl  \n",
      "4   2022-03-26   3si9xdvl  \n",
      "5   2022-03-26   3si9xdvl  \n",
      "6   2022-03-26   3si9xdvl  \n",
      "7   2022-03-26   3si9xdvl  \n",
      "8   2022-03-26   3si9xdvl  \n",
      "9   2022-03-26   3si9xdvl  \n",
      "10  2022-03-26   3si9xdvl  \n",
      "11  2022-03-26   3si9xdvl  \n",
      "12  2022-03-26   3si9xdvl  \n",
      "13  2022-03-26   3si9xdvl  \n",
      "14  2022-03-26   3si9xdvl  \n",
      "15  2022-03-26   3si9xdvl  \n",
      "16  2022-03-26   3si9xdvl  \n",
      "17  2022-03-26   3si9xdvl  \n",
      "18  2022-03-26   3si9xdvl  \n",
      "19  2022-03-26   3si9xdvl  \n"
     ]
    }
   ],
   "source": [
    "# Want to see all rows\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d3829b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "New OOD forest_env",
   "language": "python",
   "name": "forest_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
